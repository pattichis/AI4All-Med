{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPDY15AFJhICl5uucNTuat3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pattichis/AI4All-Med/blob/main/Session_3_1_tensors_and_convolution_simplified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Convolution Using Tensors"
      ],
      "metadata": {
        "id": "6rlZ0S5rC9TX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goals:"
      ],
      "metadata": {
        "id": "z0bAX5UanqaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Introduce tensors.\n",
        "2. Introduce convolution using tensors."
      ],
      "metadata": {
        "id": "cZ-FkelvnqdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the libraries"
      ],
      "metadata": {
        "id": "4SPIxecPnqvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "import matplotlib.patches as patches"
      ],
      "metadata": {
        "id": "Kkp0FOjij7OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors"
      ],
      "metadata": {
        "id": "80v4ybPoqZmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a tensor"
      ],
      "metadata": {
        "id": "dbgVg9kFnGrs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Study the outputs.\n",
        "2. Comment on the values and dimensions.\n",
        "3. What is \"Predictably random\" here?"
      ],
      "metadata": {
        "id": "MnIAWE4ImzU4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULIxy2fgok6n"
      },
      "outputs": [],
      "source": [
        "print(\"Standard methods:\")\n",
        "print(\" zeros  = \\n\", torch.zeros(2, 3))\n",
        "print(\" ones   = \\n\", torch.ones(2, 3))\n",
        "print(\" empty  = \\n\", torch.empty(2, 3))\n",
        "print(\" \")\n",
        "\n",
        "print(\"Random methods:\")\n",
        "print(\" random1 = \\n\", torch.randn(2, 3)) # mean=0, std dev=1\n",
        "print(\" random2 = \\n\", torch.randn(2, 3))\n",
        "print(\" \")\n",
        "\n",
        "print(\"Predictably random methods:\")\n",
        "torch.manual_seed(1729)\n",
        "print(\" random1 = \\n\", torch.randn(2, 3)) # mean=0, std dev=1\n",
        "torch.manual_seed(1729)\n",
        "print(\" random2 = \\n\", torch.randn(2, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolution"
      ],
      "metadata": {
        "id": "ZuLvIjR-sbpr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Small convolution example"
      ],
      "metadata": {
        "id": "7GvDfUj0zyZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Study the code and plots and then:\n",
        "1. Change the image input. You can make it as large as you want.\n",
        "2. Change conv3 to be all 1. This is an average filter.\n",
        "3. Chanve conv4 to whatever you like.\n",
        "\n",
        "After you finish your changes, run the code and take a look at the outputs."
      ],
      "metadata": {
        "id": "0eWTj5sGzYkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image to process.\n",
        "# Image input (1x1x5x5 image)\n",
        "input = torch.tensor([[[[0, 0, 0, 0, 0],\n",
        "                        [0, 1, 1, 1, 1],\n",
        "                        [0, 1, 1, 1, 1],\n",
        "                        [0, 1, 1, 1, 1],\n",
        "                        [0, 1, 1, 1, 1]]]], dtype=torch.float32)\n",
        "\n",
        "# Define convolution layer with 1 output channel and 3x3 kernel\n",
        "conv1 = nn.Conv2d(1, 1, 3, padding=0, bias=False)\n",
        "conv2 = nn.Conv2d(1, 1, 3, padding=0, bias=False)\n",
        "conv3 = nn.Conv2d(1, 1, 3, padding=0, bias=False)\n",
        "conv4 = nn.Conv2d(1, 1, 3, padding=0, bias=False)\n",
        "\n",
        "# Set weights for edge detection from left to right:\n",
        "conv1.weight.data = torch.tensor([[[[-1, 0, 1],\n",
        "                                    [-1, 0, 1],\n",
        "                                    [-1, 0, 1]]]], dtype=torch.float32)\n",
        "\n",
        "# Set weights for edge detection from top to bottom:\n",
        "conv2.weight.data = torch.tensor([[[[-1,  -1, -1],\n",
        "                                    [ 0,   0,  0],\n",
        "                                    [ 1,   1,  1]]]], dtype=torch.float32)\n",
        "\n",
        "# Create a mask of all 1s here.\n",
        "conv3.weight.data = torch.tensor([[[[1,  1, 1],\n",
        "                                    [ 1,   1,  1],\n",
        "                                    [ 1,   1,  1]]]], dtype=torch.float32)\n",
        "\n",
        "# Create whatever you like here!\n",
        "conv4.weight.data = torch.tensor([[[[-1,  -1, -1],\n",
        "                                    [ 0,   0,  0],\n",
        "                                    [ 1,   1,  1]]]], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "hM7fgztnsgDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply convolutions"
      ],
      "metadata": {
        "id": "Ere_sNsv0BPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out1 = conv1(input)\n",
        "out2 = conv2(input)\n",
        "out3 = conv3(input)\n",
        "out4 = conv4(input)"
      ],
      "metadata": {
        "id": "etEqOur70EWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolution Animation"
      ],
      "metadata": {
        "id": "mN8gXSsf01Ed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Discuss how the output reflects the convolution kernel.\n",
        "\n",
        "You can animate any one of the convolutions by changing:\n",
        "1. kernel_image\n",
        "2. output_image\n"
      ],
      "metadata": {
        "id": "DzoLdSKq01Pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract 2D arrays for display\n",
        "input_image2 = input[0, 0].detach().numpy()\n",
        "kernel_image = conv1.weight[0, 0].detach().numpy()\n",
        "output_image = out1[0, 0].detach().numpy()\n",
        "\n",
        "# Pretty-print with fixed precision and alignment\n",
        "with np.printoptions(precision=2, suppress=True):\n",
        "    print(\"input image  = \\n\", input_image2)\n",
        "    print(\"output image = \\n\", output_image)\n",
        "    print(\"convolution kernel = \\n\", kernel_image)\n"
      ],
      "metadata": {
        "id": "S3x_FscY1Joe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: To save in GitHub, CLEAR THE OUTPUT\n",
        "\n",
        "# Define interactive plot function\n",
        "def show_step(step):\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    ax.imshow(input_image2, cmap='gray')\n",
        "    ax.set_xticks(range(5))\n",
        "    ax.set_yticks(range(5))\n",
        "    ax.set_title(f\"Step {step+1}\")\n",
        "\n",
        "    # Compute kernel position\n",
        "    row = step // 3\n",
        "    col = step % 3\n",
        "\n",
        "    # Draw kernel window\n",
        "    rect = patches.Rectangle((col - 0.5, row - 0.5), 3, 3,\n",
        "                             linewidth=2, edgecolor='red', facecolor='none')\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "    # Extract the subregion\n",
        "    region = input_image2[row:row+3, col:col+3]\n",
        "    result = np.sum(region * kernel_image)\n",
        "\n",
        "    # Overlay values\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            ax.text(col + j, row + i,\n",
        "                    str(int(region[i, j])),\n",
        "                    color='blue', ha='center', va='center')\n",
        "\n",
        "    # Show output value\n",
        "    ax.text(0, 5.5, f\"Output[{row}, {col}] = {result:.1f}\",\n",
        "            fontsize=14, color='green')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Create slider and display\n",
        "slider = widgets.IntSlider(value=0, min=0, max=8, step=1, description='Step:')\n",
        "widgets.interact(show_step, step=slider)\n"
      ],
      "metadata": {
        "id": "fr6bKARo01gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HAZKhYn807TD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How convolution is applied"
      ],
      "metadata": {
        "id": "U8MU9a0_2h3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Study the example for the [0, 0] pixel.<br>\n",
        "Verify the outputs for:\n",
        "1. Output[0, 1].\n",
        "2. Output[2, 2].\n",
        "3. Output[2, 0]"
      ],
      "metadata": {
        "id": "hxxG-ECo2h7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first pixel is calculated using:\n",
        "$$\n",
        "\\text{Input patch} =\n",
        "\\begin{bmatrix}\n",
        "0 & 0 & 0 \\\\\n",
        "0 & 1 & 1 \\\\\n",
        "0 & 1 & 1 \\\\\n",
        "\\end{bmatrix}\n",
        "\\quad\n",
        "\\text{Kernel} =\n",
        "\\begin{bmatrix}\n",
        "-1 & 0 & 1 \\\\\n",
        "-1 & 0 & 1 \\\\\n",
        "-1 & 0 & 1 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "Multiply corresponding pixels:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\text{Output}[0,0] &=\n",
        "         (0 \\times -1) + (0 \\times 0) + (0 \\times 1) \\\\\n",
        "&\\quad + (0 \\times -1) + (1 \\times 0) + (1 \\times 1) \\\\\n",
        "&\\quad + (0 \\times -1) + (1 \\times 0) + (1 \\times 1) \\\\\n",
        "&= 1 + 1  \\\\\n",
        "&= 2\n",
        "\\end{aligned}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "lfRC-Mgr2kLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot the results"
      ],
      "metadata": {
        "id": "ksyVZuNB44oV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots\n",
        "plt.figure(figsize=(12, 9))\n",
        "\n",
        "# conv1\n",
        "plt.subplot(4, 3, 1)\n",
        "plt.title(\"Input Image\")\n",
        "plt.imshow(input_image2, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(4, 3, 2)\n",
        "plt.title(\"Kernel (Filter) 1\")\n",
        "plt.imshow(conv1.weight[0, 0].detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(4, 3, 3)\n",
        "plt.title(\"Output Image\")\n",
        "plt.imshow(out1[0, 0].detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "# conv2\n",
        "plt.subplot(4, 3, 4)\n",
        "plt.title(\"Input Image\")\n",
        "plt.imshow(input_image2, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(4, 3, 5)\n",
        "plt.title(\"Kernel (Filter) 2\")\n",
        "plt.imshow(conv2.weight[0, 0].detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(4, 3, 6)\n",
        "plt.title(\"Output Image\")\n",
        "plt.imshow(out2[0, 0].detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "# conv3\n",
        "plt.subplot(4, 3, 7)\n",
        "plt.title(\"Input Image\")\n",
        "plt.imshow(input_image2, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(4, 3, 8)\n",
        "plt.title(\"Kernel (Filter) 3\")\n",
        "plt.imshow(conv3.weight[0, 0].detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(4, 3, 9)\n",
        "plt.title(\"Output Image\")\n",
        "plt.imshow(out3[0, 0].detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "# conv4\n",
        "plt.subplot(4, 3, 10)\n",
        "plt.title(\"Input Image\")\n",
        "plt.imshow(input_image2, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(4, 3, 11)\n",
        "plt.title(\"Kernel (Filter) 4\")\n",
        "plt.imshow(conv4.weight[0, 0].detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(4, 3, 12)\n",
        "plt.title(\"Output Image\")\n",
        "plt.imshow(out4[0, 0].detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "mWBCn_uypU3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform convolution on real images"
      ],
      "metadata": {
        "id": "jEIvwxo7C6Rk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the images to visualize"
      ],
      "metadata": {
        "id": "96YPNEDK5sFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Use the up arrow to upload your own image.\n",
        "2. Change the filename to the image that you uploaded.\n"
      ],
      "metadata": {
        "id": "HX9ABTUa5wWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://raw.githubusercontent.com/pattichis/GraphSpeeds2/main/Elephant.png\n",
        "!wget -nc https://raw.githubusercontent.com/pattichis/GraphSpeeds2/main/Squirrel.png\n",
        "!wget -nc https://raw.githubusercontent.com/pattichis/GraphSpeeds2/main/Tortoise.jpg\n",
        "!wget -nc https://raw.githubusercontent.com/pattichis/GraphSpeeds2/main/Koala.jpeg"
      ],
      "metadata": {
        "id": "1URHIm9tBKnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select image to process"
      ],
      "metadata": {
        "id": "XvslZnpBNuJO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the input image.\n"
      ],
      "metadata": {
        "id": "MojiwPaUNxAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow  # use cv2_imshow in Colab\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Select from Elephant.png, Squirrel.png, Tortoise.jpg, Koala.jpeg\n",
        "\n",
        "filename=\"Koala.jpeg\"\n",
        "image = cv2.imread(filename)\n",
        "print(image.shape)\n",
        "cv2_imshow(image)\n",
        "\n",
        "img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "cv2_imshow(img)\n",
        "\n"
      ],
      "metadata": {
        "id": "AMlIjtzcyhf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert the input image to grayscale"
      ],
      "metadata": {
        "id": "pZQubAlW9xby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should not need to change this step."
      ],
      "metadata": {
        "id": "BITW-Mc49xjQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1927e5e1"
      },
      "source": [
        "grayscale_img_array = np.array(img)\n",
        "\n",
        "# Convert to torch tensor and add batch and channel dimensions\n",
        "input_image_tensor = torch.tensor(grayscale_img_array, dtype=torch.float32).unsqueeze(0).unsqueeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select which filter you want to apply:"
      ],
      "metadata": {
        "id": "-LpbgTbW9dLD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can change this to conv1, conv2, conv3, conv4, ..."
      ],
      "metadata": {
        "id": "3v5WT7vN9dR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the convolution\n",
        "output_image_tensor = conv1(input_image_tensor)"
      ],
      "metadata": {
        "id": "uzSbyxRN9dkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup the output image for display"
      ],
      "metadata": {
        "id": "X4aeV6eJ82gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert output to numpy array for display\n",
        "output_image_array = output_image_tensor[0, 0].detach().numpy()\n",
        "output_image_array = -np.abs(output_image_array)\n",
        "#output_image_array = (output_image_array - output_image_array.min()) / (output_image_array.max() - output_image_array.min()) * 255"
      ],
      "metadata": {
        "id": "rjHJ74HJ9K4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot the input and output images"
      ],
      "metadata": {
        "id": "CvS0zspX82u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the original and convolved images\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Original Grayscale Image\")\n",
        "plt.imshow(grayscale_img_array, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Convolved Image\")\n",
        "plt.imshow(output_image_array, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0KX7A6Fm826r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = img\n",
        "\n",
        "out1 = conv1(input_image_tensor)\n",
        "out2 = conv2(input_image_tensor)\n",
        "out3 = conv3(input_image_tensor)\n",
        "out4 = conv4(input_image_tensor)"
      ],
      "metadata": {
        "id": "jNsftfyp7YwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "# conv1\n",
        "plt.subplot(4, 3, 1)\n",
        "plt.title(\"Input Image\")\n",
        "plt.imshow(input_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(4, 3, 2)\n",
        "plt.title(\"Kernel (Filter) 1\")\n",
        "plt.imshow(conv1.weight[0, 0].detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(4, 3, 3)\n",
        "plt.title(\"Output Image\")\n",
        "plt.imshow(out1[0, 0].detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "# conv2\n",
        "plt.subplot(4, 3, 4)\n",
        "plt.title(\"Input Image\")\n",
        "plt.imshow(input_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(4, 3, 5)\n",
        "plt.title(\"Kernel (Filter) 2\")\n",
        "plt.imshow(conv2.weight[0, 0].detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(4, 3, 6)\n",
        "plt.title(\"Output Image\")\n",
        "plt.imshow(out2[0, 0].detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "# conv3\n",
        "plt.subplot(4, 3, 7)\n",
        "plt.title(\"Input Image\")\n",
        "plt.imshow(input_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(4, 3, 8)\n",
        "plt.title(\"Kernel (Filter) 3\")\n",
        "plt.imshow(conv3.weight[0, 0].detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(4, 3, 9)\n",
        "plt.title(\"Output Image\")\n",
        "plt.imshow(out3[0, 0].detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "# conv4\n",
        "plt.subplot(4, 3, 10)\n",
        "plt.title(\"Input Image\")\n",
        "plt.imshow(input_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(4, 3, 11)\n",
        "plt.title(\"Kernel (Filter) 4\")\n",
        "plt.imshow(conv4.weight[0, 0].detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(4, 3, 12)\n",
        "plt.title(\"Output Image\")\n",
        "plt.imshow(out4[0, 0].detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZH2z1J757Zmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ViqjW3f9TSE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}